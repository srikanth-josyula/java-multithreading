package org.sample.nodes;

import java.util.Set;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
import java.util.stream.Collectors;
import java.util.stream.IntStream;
import java.util.stream.Stream;

import org.json.JSONArray;
import org.sample.scripts.AlfrescoQueryOps;

public class GetNodeProperties {

    private final static int SKIP_COUNT = Integer.parseInt("20");  // Use Integer.parseInt for converting string to int
    private final static String SEARCH_QUERY = "SITE:'test' AND cm:creator:'josyusr' AND TYPE:'jh:JHDocument'";

    public static void main(String[] args) {
        int pageNum = 0;       // Start page number

        AlfrescoQueryOps alfOps = new AlfrescoQueryOps();
        int maxLimit = alfOps.getmaxNodeCountOkHTTP(SEARCH_QUERY);  // Get max node count from Alfresco
        
        System.out.println("Total documents found for Admin: " + maxLimit);

        // Define a thread pool of size 3
        ExecutorService executor = Executors.newFixedThreadPool(3);

        // Submit tasks to the executor for each page range
        Set<Future<Set<String>>> futures = Stream.iterate(pageNum, i -> i < maxLimit, i -> i + SKIP_COUNT)
                .map(i -> executor.submit(() -> {
                    System.out.println(Thread.currentThread().getName() + " processing range starting from " + i);
                    Set<String> nodeIDList = processNodeDetails(alfOps, i, SEARCH_QUERY);
                    return nodeIDList;
                }))
                .collect(Collectors.toSet());

        // Wait for all tasks to complete and print the size of each nodeIDList
        futures.forEach(future -> {
            try {
                Set<String> nodeIDList = future.get(); // Wait for task to complete
                System.out.println("Processed node ID list size: " + nodeIDList.size());
            } catch (Exception e) {
                e.printStackTrace();
            }
        });

        // Shutdown the executor after all tasks are completed
        executor.shutdown();
        try {
            if (!executor.awaitTermination(60, java.util.concurrent.TimeUnit.SECONDS)) {
                System.err.println("Executor did not terminate in the specified time.");
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        System.out.println("All tasks completed. Exiting program.");
    }

    // Process the node details for a given page number and search query
    private static Set<String> processNodeDetails(AlfrescoQueryOps alfOps, int pageNum, String searchQuery) {
        // Get the node details as a JSONArray
        JSONArray dataJsonArr = alfOps.getNodeDetailsOkHTTP(pageNum, searchQuery).getJSONObject("list")
                .getJSONArray("entries");
        
        // Extract node IDs from the entries in the response
        return IntStream.range(0, dataJsonArr.length())
                .mapToObj(i -> dataJsonArr.getJSONObject(i).getJSONObject("entry").getString("id"))
                .collect(Collectors.toSet());
    }
}
