package org.sample.nodes;

import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;
import java.util.stream.IntStream;

import org.json.JSONArray;
import org.sample.scripts.AlfrescoQueryOps;

public class GetNodeProperties {

    private final static int SKIP_COUNT = Integer.parseInt("20");  // Use Integer.parseInt for converting string to int
    
    private final static String SEARCH_QUERY = "SITE:'test' AND cm:creator:'josyusr' AND TYPE:'jh:JHDocument'";

    public static void main(String[] args) throws InterruptedException {
        int pageNum = 0;       // Start page number
        
        AlfrescoQueryOps alfOps = new AlfrescoQueryOps();
        int maxLimit = alfOps.getmaxNodeCountOkHTTP(SEARCH_QUERY);  // Get max node count from Alfresco
        
        System.out.println("Total documents found for Admin: " + maxLimit);
        
        ExecutorService executor = Executors.newFixedThreadPool(3);
        
        // Use a thread-safe set to store node IDs
        Set<String> nodeIDList = ConcurrentHashMap.newKeySet();

        IntStream.iterate(pageNum, i -> i < maxLimit, i -> i + SKIP_COUNT)
                .forEach(i -> {
                    executor.submit(() -> {
                        System.out.println(Thread.currentThread().getName() + " processing range starting from " + i);
                        Set<String> pageNodeIDs = processNodeDetails(alfOps, i, SEARCH_QUERY);
                        
                        // Add the IDs from this page to the overall nodeIDList
                        nodeIDList.addAll(pageNodeIDs);
                    });
                });
        
        // Shut down the executor after submitting all tasks
        executor.shutdown();
        
        // Wait for all tasks to finish
        if (!executor.awaitTermination(1, TimeUnit.HOURS)) {
            System.out.println("Timeout exceeded before completing all tasks.");
        }
        
        // Print the size of the nodeIDList after all threads finish
        System.out.println("Total number of node IDs: " + nodeIDList.size());
    }
    
    private static Set<String> processNodeDetails(AlfrescoQueryOps alfOps, int pageNum, String searchQuery) {
        JSONArray dataJsonArr = alfOps.getNodeDetailsOkHTTP(pageNum, searchQuery).getJSONObject("list")
                .getJSONArray("entries");
        
        return IntStream.range(0, dataJsonArr.length())
                .mapToObj(i -> dataJsonArr.getJSONObject(i).getJSONObject("entry").getString("id"))
                .collect(Collectors.toSet());
    }
}
